{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bbc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9496148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('reviewsforpractice.xlsx')\n",
    "df = df.reset_index().rename(columns={'index':'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d144dbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='tf')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668278ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in range(len(df)):\n",
    "    res[df['ID'][i]]= polarity_scores_roberta(df['Reviews'][i])\n",
    "results = pd.DataFrame(res).T\n",
    "results = results.reset_index().rename(columns={'index':'ID'})\n",
    "results = results.merge(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb46073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.030721</td>\n",
       "      <td>0.963283</td>\n",
       "      <td>I wrote this review after 15 days using..\\nBat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.982777</td>\n",
       "      <td>I like this mobile üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.974916</td>\n",
       "      <td>T2x awesome pictures best smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.009596</td>\n",
       "      <td>0.988582</td>\n",
       "      <td>Beautiful phoneüì± camera is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.073202</td>\n",
       "      <td>0.922002</td>\n",
       "      <td>Only charging is slow other wise all features ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>3111</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.966105</td>\n",
       "      <td>Best 5g phone this range and this sagment and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>3112</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.985725</td>\n",
       "      <td>amazing product. Thanks for timely delivered i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>3113</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.064185</td>\n",
       "      <td>0.931951</td>\n",
       "      <td>Decent phone with good camera and\\nperformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>3114</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.988721</td>\n",
       "      <td>My favorite brand, and new product ‚ú®Ô∏è üòç üôå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>3115</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>0.970346</td>\n",
       "      <td>Nice and awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3116 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  roberta_neg  roberta_neu  roberta_pos  \\\n",
       "0        0     0.005996     0.030721     0.963283   \n",
       "1        1     0.001393     0.015830     0.982777   \n",
       "2        2     0.002595     0.022489     0.974916   \n",
       "3        3     0.001822     0.009596     0.988582   \n",
       "4        4     0.004795     0.073202     0.922002   \n",
       "...    ...          ...          ...          ...   \n",
       "3111  3111     0.002451     0.031445     0.966105   \n",
       "3112  3112     0.001552     0.012723     0.985725   \n",
       "3113  3113     0.003864     0.064185     0.931951   \n",
       "3114  3114     0.000953     0.010326     0.988721   \n",
       "3115  3115     0.002764     0.026889     0.970346   \n",
       "\n",
       "                                                Reviews  \n",
       "0     I wrote this review after 15 days using..\\nBat...  \n",
       "1                                  I like this mobile üòä  \n",
       "2                  T2x awesome pictures best smartphone  \n",
       "3                       Beautiful phoneüì± camera is good  \n",
       "4     Only charging is slow other wise all features ...  \n",
       "...                                                 ...  \n",
       "3111  Best 5g phone this range and this sagment and ...  \n",
       "3112  amazing product. Thanks for timely delivered i...  \n",
       "3113     Decent phone with good camera and\\nperformance  \n",
       "3114          My favorite brand, and new product ‚ú®Ô∏è üòç üôå  \n",
       "3115                                   Nice and awesome  \n",
       "\n",
       "[3116 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c102d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1+cu118 with CUDA 1108 (you have 2.0.1)\n",
      "    Python  3.11.4 (you have 3.11.4)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "senti = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e619c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9801220893859863}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9987383484840393}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997095465660095}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998781681060791}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9960464835166931}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998106360435486}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997652173042297}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997425675392151}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9988940358161926}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9995157718658447}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997652173042297}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997904896736145}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998546838760376}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997970461845398}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999813973903656}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997900128364563}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9948177933692932}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9985906481742859}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9919217824935913}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999875545501709}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996558427810669}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996203184127808}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996938705444336}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9957543611526489}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996970891952515}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9993791580200195}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998652935028076}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5464053153991699}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9916389584541321}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9979066848754883}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998360872268677}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996829032897949}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9924046397209167}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998735189437866}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9992964267730713}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998657703399658}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9893049001693726}]\n",
      "[{'label': 'POSITIVE', 'score': 0.860135018825531}]\n",
      "[{'label': 'POSITIVE', 'score': 0.99959796667099}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9995354413986206}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999504566192627}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994761347770691}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9779561758041382}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994097948074341}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9981657862663269}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997716546058655}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9971488118171692}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9619550704956055}]\n",
      "[{'label': 'POSITIVE', 'score': 0.97652268409729}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9918718934059143}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.8901695609092712}]\n",
      "[{'label': 'POSITIVE', 'score': 0.8836358785629272}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9681936502456665}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9980599284172058}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9976123571395874}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9853734970092773}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9993646740913391}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9638676047325134}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998811483383179}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9823285937309265}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999824583530426}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998733997344971}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5056593418121338}]\n",
      "[{'label': 'POSITIVE', 'score': 0.998573899269104}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998412132263184}]\n",
      "[{'label': 'POSITIVE', 'score': 0.6597938537597656}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9955052137374878}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9992814660072327}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9990940093994141}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996242523193359}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9932228326797485}]\n",
      "[{'label': 'POSITIVE', 'score': 0.8093093633651733}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998719692230225}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999870777130127}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998726844787598}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997281432151794}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9980759620666504}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9869868159294128}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.7025341987609863}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994816184043884}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996678829193115}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998559951782227}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996699094772339}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997944235801697}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9617843627929688}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998725652694702}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9969032406806946}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9986431002616882}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998581409454346}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998403787612915}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996015429496765}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9725031852722168}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9968641400337219}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9716438055038452}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9978365302085876}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998735189437866}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9969732761383057}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9983003735542297}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998735189437866}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.999747097492218}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9850748777389526}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9995080232620239}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9715245962142944}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9893633723258972}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998695850372314}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996770620346069}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998311996459961}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9974715709686279}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998629093170166}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9982966780662537}]\n",
      "[{'label': 'POSITIVE', 'score': 0.998957633972168}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997689127922058}]\n",
      "[{'label': 'POSITIVE', 'score': 0.989768385887146}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994590878486633}]\n",
      "[{'label': 'POSITIVE', 'score': 0.7745133638381958}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9990442395210266}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.997215747833252}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9698706269264221}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9985665678977966}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996813535690308}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994007349014282}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9995697140693665}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9933360815048218}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9998088479042053}]\n",
      "[{'label': 'POSITIVE', 'score': 0.8116946220397949}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9739218354225159}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997525811195374}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9995160102844238}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9977725148200989}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998735189437866}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996428489685059}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997411370277405}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996981620788574}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9559434056282043}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9715350866317749}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997867941856384}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997202754020691}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997722506523132}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997889399528503}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9995166063308716}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9995003938674927}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9994757771492004}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9866499304771423}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9770721793174744}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996299743652344}]\n",
      "[{'label': 'POSITIVE', 'score': 0.8580190539360046}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998641014099121}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9973005652427673}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998606443405151}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9986157417297363}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9993253946304321}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997848868370056}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.998803973197937}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9970763921737671}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9750732779502869}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996923208236694}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9997300505638123}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9881234765052795}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997982382774353}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9995273351669312}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9993730187416077}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998558759689331}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998216032981873}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999870777130127}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994561076164246}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996587038040161}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998846054077148}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997857213020325}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999864935874939}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998645782470703}]\n",
      "[{'label': 'POSITIVE', 'score': 0.7352967262268066}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994630217552185}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999870777130127}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994198083877563}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9988200068473816}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9967508316040039}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9982707500457764}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9802605509757996}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9994956254959106}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9978097081184387}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9651119112968445}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998763799667358}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9995155334472656}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9985350370407104}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997650980949402}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997001886367798}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998310804367065}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997633099555969}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997634291648865}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9976668357849121}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9983539581298828}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9840803742408752}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9995521903038025}]\n",
      "[{'label': 'POSITIVE', 'score': 0.999624490737915}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998577833175659}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.999765932559967}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997705817222595}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9963621497154236}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9998039603233337}]\n",
      "[{'label': 'POSITIVE', 'score': 0.997188150882721}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996328353881836}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998794794082642}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997478127479553}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9932674169540405}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998723268508911}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9989945292472839}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9925922155380249}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9876338243484497}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996281862258911}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998413324356079}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9918439984321594}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9855843186378479}]\n",
      "[{'label': 'POSITIVE', 'score': 0.997940719127655}]\n",
      "[{'label': 'POSITIVE', 'score': 0.98740154504776}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997736811637878}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9992151260375977}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998781681060791}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9890604019165039}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997441172599792}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997724890708923}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9991348385810852}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9974673986434937}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.903209388256073}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9988980293273926}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9973000884056091}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998102784156799}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998383522033691}]\n",
      "[{'label': 'POSITIVE', 'score': 0.7948167324066162}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9991389513015747}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9895943403244019}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998217225074768}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998279809951782}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9996744394302368}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9858074188232422}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997333884239197}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9755522608757019}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9411745667457581}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9986628293991089}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9090782999992371}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9994527697563171}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9952993392944336}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9716672301292419}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9997205138206482}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998756647109985}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9996383190155029}]\n",
      "[{'label': 'POSITIVE', 'score': 0.6920052170753479}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998761415481567}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m ress \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m----> 3\u001b[0m     ress[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m][i]]\u001b[38;5;241m=\u001b[39m senti(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviews\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ress[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m][i]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1122\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1115\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1116\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         )\n\u001b[0;32m   1120\u001b[0m     )\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1129\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1128\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1129\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1130\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1028\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1027\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1028\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1029\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:788\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    786\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 788\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[0;32m    789\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    790\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    791\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    792\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    793\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    794\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    795\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    796\u001b[0m )\n\u001b[0;32m    797\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:608\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    604\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    606\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    609\u001b[0m     x\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m    610\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    611\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    612\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    613\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    614\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    615\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:375\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    368\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    369\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    370\u001b[0m         hidden_state,\n\u001b[0;32m    371\u001b[0m         attn_mask,\n\u001b[0;32m    372\u001b[0m         head_mask[i],\n\u001b[0;32m    373\u001b[0m     )\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    376\u001b[0m         hidden_state,\n\u001b[0;32m    377\u001b[0m         attn_mask,\n\u001b[0;32m    378\u001b[0m         head_mask[i],\n\u001b[0;32m    379\u001b[0m         output_attentions,\n\u001b[0;32m    380\u001b[0m     )\n\u001b[0;32m    382\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:295\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    296\u001b[0m     query\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    297\u001b[0m     key\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    298\u001b[0m     value\u001b[38;5;241m=\u001b[39mx,\n\u001b[0;32m    299\u001b[0m     mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[0;32m    300\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    301\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    302\u001b[0m )\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    304\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:217\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    215\u001b[0m q \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_lin(query))  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    216\u001b[0m k \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    219\u001b[0m q \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(dim_per_head)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    220\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ress = {}\n",
    "for i in range(len(df)):\n",
    "    ress[df['ID'][i]]= senti(df['Reviews'][i])\n",
    "    print(ress[df['ID'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e84b7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>0</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9801220893859...</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.030721</td>\n",
       "      <td>0.963283</td>\n",
       "      <td>I wrote this review after 15 days using..\\nBat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9987383484840...</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.982777</td>\n",
       "      <td>I like this mobile üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9997095465660...</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.974916</td>\n",
       "      <td>T2x awesome pictures best smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9998781681060...</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.009596</td>\n",
       "      <td>0.988582</td>\n",
       "      <td>Beautiful phoneüì± camera is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9960464835166...</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.073202</td>\n",
       "      <td>0.922002</td>\n",
       "      <td>Only charging is slow other wise all features ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>3111</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9993752837181...</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.966105</td>\n",
       "      <td>Best 5g phone this range and this sagment and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>3112</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9998685121536...</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.985725</td>\n",
       "      <td>amazing product. Thanks for timely delivered i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>3113</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9996556043624...</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.064185</td>\n",
       "      <td>0.931951</td>\n",
       "      <td>Decent phone with good camera and\\nperformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>3114</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9901899695396...</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.988721</td>\n",
       "      <td>My favorite brand, and new product ‚ú®Ô∏è üòç üôå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>3115</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9998748302459...</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>0.970346</td>\n",
       "      <td>Nice and awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3116 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                                  0  roberta_neg  \\\n",
       "0        0  {'label': 'POSITIVE', 'score': 0.9801220893859...     0.005996   \n",
       "1        1  {'label': 'POSITIVE', 'score': 0.9987383484840...     0.001393   \n",
       "2        2  {'label': 'POSITIVE', 'score': 0.9997095465660...     0.002595   \n",
       "3        3  {'label': 'POSITIVE', 'score': 0.9998781681060...     0.001822   \n",
       "4        4  {'label': 'POSITIVE', 'score': 0.9960464835166...     0.004795   \n",
       "...    ...                                                ...          ...   \n",
       "3111  3111  {'label': 'POSITIVE', 'score': 0.9993752837181...     0.002451   \n",
       "3112  3112  {'label': 'POSITIVE', 'score': 0.9998685121536...     0.001552   \n",
       "3113  3113  {'label': 'POSITIVE', 'score': 0.9996556043624...     0.003864   \n",
       "3114  3114  {'label': 'POSITIVE', 'score': 0.9901899695396...     0.000953   \n",
       "3115  3115  {'label': 'POSITIVE', 'score': 0.9998748302459...     0.002764   \n",
       "\n",
       "      roberta_neu  roberta_pos  \\\n",
       "0        0.030721     0.963283   \n",
       "1        0.015830     0.982777   \n",
       "2        0.022489     0.974916   \n",
       "3        0.009596     0.988582   \n",
       "4        0.073202     0.922002   \n",
       "...           ...          ...   \n",
       "3111     0.031445     0.966105   \n",
       "3112     0.012723     0.985725   \n",
       "3113     0.064185     0.931951   \n",
       "3114     0.010326     0.988721   \n",
       "3115     0.026889     0.970346   \n",
       "\n",
       "                                                Reviews  \n",
       "0     I wrote this review after 15 days using..\\nBat...  \n",
       "1                                  I like this mobile üòä  \n",
       "2                  T2x awesome pictures best smartphone  \n",
       "3                       Beautiful phoneüì± camera is good  \n",
       "4     Only charging is slow other wise all features ...  \n",
       "...                                                 ...  \n",
       "3111  Best 5g phone this range and this sagment and ...  \n",
       "3112  amazing product. Thanks for timely delivered i...  \n",
       "3113     Decent phone with good camera and\\nperformance  \n",
       "3114          My favorite brand, and new product ‚ú®Ô∏è üòç üôå  \n",
       "3115                                   Nice and awesome  \n",
       "\n",
       "[3116 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d285a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
